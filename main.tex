\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{enumitem}
\usepackage{listings}
\usepackage{authblk}
\usepackage{appendix}

\lstset{
  basicstyle=\ttfamily,
  mathescape
}

\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{conjecture}{Conjecture}

\title{CS 2051: On Computability of Meta-Interpreters}

\author[1]{Govind Gnanakumar}
\author[1]{Sidharth Baskaran}
\author[1]{Shikhar Ahuja}
\affil[1]{College of Computing, Georgia Institute of Technology}

\date{April 9, 2023}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

\section{Background}
% This section should develop the basic definitions and
% preliminary results required for the statement and proof of
% your main result, including examples that help the reader to
% develop intuition for the concepts presented. Start from scratch, remember your audience is other 2051 students.

\subsection{Overview}

Before we can understand how the principles of computability--which outlines problems that are computationally tractable--apply to meta-interpreters, we must first specify what we mean by a meta-interpreter, because even in the broader context of programming language theory, this is something that is rather ill-defined. Most generally, a meta-interpreter is an interpreter for a language that is written in itself (as the vast majority of programming languages are today). For example, interpreting a lambda application may be implemented using function application. But for the purposes of this paper, we shall differentiate between the three concepts commonly identified with meta-interpretation: self-recognizers, self-interpreters, and self-evaluators.
\begin{enumerate}
    \item A self-interpreter takes a source term representation in some plain format (such as a string of characters) and returns a representation of the corresponding normalized term, which is something that can be represented solely by core language features.
    \item A self-recognizer takes a typed representation and returns an plain form.
    \item A self-evaluator takes a typed representation and returns a reduced typed representation.
\end{enumerate}

% Suppose in our language the expression $e$ evaluates to $v$;
% the typed representation of a term $t$ is denoted as \verb|typed_rep(t)|;
% the plain representation (e.g. string) of a term $t$ is denoted as \verb|plain_rep(t)|. Then we have (note that those things are not types but input-output correspondences) \verb|self-recognizer: typed_rep(f) -> f| and
% \verb|plain-interpreter: plain_rep(<f, x>) -> plain_rep(f(x))|.

% WHERE DOES ALL OF ABOVE PARA FIT IN MAYBE PUT IN OWN SECTION

% Define Godel encoding
% Defining formal grammars seems unnecessary
% Define recursively enumerable languages, and their subsets
% We shall define recursively enumerable languages, and their subsets
% Defining combinators seems unnecessary
% Define STLC, SKI combinators, Y Combinator, etc
% We shall define STLC, SKI combinators, Y combinator, etc
% Define the specifications of System F-omega (refer to appendix), and its position in the broader context of the Lambda Cube.


\subsection{Lambda Calculus}

A $\lambda$ calculus is defined as the smallest, or most fundamental programming language. It operates solely on the concepts of variable substitution and function definitions. We a present a brief introduction to this language as a means of expressing computable functions in a mathematical language for a theoretical approach. An \textit{expression} can be either a name (i.e. variable or identifier), function, or application. Functions operate on names and expressions, and applications are effectively compositions of expressions. We summarize this as:

\begin{lstlisting}
    <expression> := <name>|<function>|<application>
    <function> := $\lambda$<name>.<expression>
    <application> := <expression><expression>
\end{lstlisting}

We could define the identity function as
\begin{equation*}
    \lambda x.x
\end{equation*}
Further, we perform application from left-to-right, that is for a set of expressions $\{E_i\}$:
\begin{equation*}
    E_1E_2\cdots E_n\equiv ((E_1E_2)E_3)\cdots E_n
\end{equation*}
Combining these concepts, we can apply a function to an expression as the following:
\begin{equation*}
    (\lambda x.x)y
\end{equation*}
Here, we substitute the value of $y$ into the function definition:
\begin{equation*}
    (\lambda x.x)y=[y/x]x=y
\end{equation*}
We only provide a brief overview here, but $\lambda$-calculus can perform all the basic things a programming language can, including arithmetic and logical operations.

\subsection{The Lambda Cube}
We shall investigate the Lambda Cube, and the meaning of its edges and vertices. That is, we shall discuss the semantics and reduction rules of the STLC, System F, and System F$\omega$.

\subsection{Encodings}
We shall consider one of the most common methods of dealing with uniform types in computability proofs—the Godel encoding.
The idea is that a finite list of natural numbers $\{a_0,a_1,\ldots,a_n\}$ can be encoded to single unique natural number. In other words it is an injective mapping $G:\mathbb{N}^n\to \mathbb{N}$ such that
\begin{equation*}
    G(\{a_i\})=p_0^{a_0}\cdot p_1^{a_1}\cdot \cdots \cdot p_n^{a_n}    
\end{equation*}
Since we create a prime factorization, which are unique, the function is injective. This means we can represent $n$-nary functions
as 1-ary functions since we can look at $f(\{a_i\})\implies f(p_0^{a_0}\cdot p_1^{a_1}\cdot \cdots \cdot p_n^{a_n})$.

\subsection{Computability Theorems}
We shall research the foundational tenets and proofs of computability theory—from the halting problem to the various types of recursion.

\section{Computability of Total Functional Languages}

It's widely believed that it's impossible to build a self-interpreter for a total functional language as a corollary of the halting problem. Because if a self-interpreter could be defined for a total (strongly normalizing) language, then that would mean one could pass in any term, and the compiler would reject or accept it, and thus, from a description of an arbitrary computer program and an input, know whether the program will finish running, or continue to run forever. An existence of such an interpreter violates the halting problem.
TODO: Properly explain the above with examples and maybe a proof by contradiction. EXPLAIN THE HALTING PROBLEM.

From the above, it would seem as if it was impossible to type check anything at all—but that is not the case, for we see type checkers in the real world all the time. Type checking a strict subset of all programs is possible—all this means is that there's no guarantee that a program that fails to type check actually fails to halt. It may halt, but it may also not halt—a type checker is incapable of checking every program with absolute certainty. TODO: ELABORATE WITH EXAMPLES; EXPLAIN TOTAL FUNCTIONAL LANGUAGES

EXPLAIN UNIVERSAL FUNCTIONS

EXPLAIN THE NORMALIZATION BARRIER

TODO: Existing understanding of how/why its impossible to build a self-interpreter for a total functional language, and a look into Brown and Palsberg's paper: https://web.cs.ucla.edu/~palsberg/paper/popl16-full.pdf. May also be helpful: http://lambda-the-ultimate.org/node/3076

\section{Disproving Brown and Palsberg}

% Our disproof of Brown and Palsberg's belief that they defined a self-interpreter for F-omega 
We'll approach this problem from the computability standpoint, and attempt a proof by contradiction.

\begin{definition}
A (countable) set $F$ of total functions from $N$ to $N$ is self-interpretable if and only if there exists a (possibly repetitive) list of all functions in $F$, $f_0, f_1, f_2,  ...$, such that there exists $g \in F$ satisfying $\forall i \in N$, $g(2^i3^x) = f_i(x)$.
Note: The list doesn’t need to be computably enumerable.
\end{definition}

\begin{theorem}
The set C of all computable total functions from $N$ to $N$ is not self-interpretable.
\end{theorem}

\begin{proof}
Suppose there is a list of all functions in $C$ ($c_0  c_1  c_2  ...$) such that there exists $g \in C$ satisfying  $\forall i \in N$, $g(2^i3^x)=c_i(x)$. Let $p(x) = g(2^x3^x) + 1$. Clearly, $p(x)$ is still a computable total function (because $p(x)$ consists of a computable total function, $g \in C$), so $p = c_j$ for some $j \in N$.

Now consider $p(j)$:\\
$p(j) = g(2^j3^j) + 1 = c_j(j) + 1 = p(j) + 1$.

This is a contradiction, so $C$ is not self-interpretable.
\end{proof}

We shall adopt a similar approach for finding a contradiction in selt-interpretable $F\omega$.

\begin{conjecture}
The set L of all total functions from $N$ to $N$ computable by $F\omega$ is not self-interpretable.
\end{conjecture}

\begin{proof}
    Suppose there is a list of all total functions in $L$ ($l_0, l_1, l_2, ...$) such that there exists $g \in L$ satisfying $\forall i \in N, g(<i, x>) = l_i(x)$. Let $p(x) = g(<i, x>) + 1$. Clearly, $p(x)$ is still in $L$, so $p = l_j$ for some $j \in N$. Now consider $p(j)$:\\
    $p(j)=g(<j, j>)+1=l_j(j) + 1 = p(j) + 1$.

    This is a contradiction, so $L$ is not self-interpretable.
\end{proof}

\section{Generalizations and Future Possiblities}

Although we've shown that it's impossible to create a self-interpreter for F-omega, this is only the beginning. There is still the more pressing question as to why that is the case. Is F-omega itself semantically ill-defined, and if we specify a type checker as a constant function primitive, does that mean it is impossible to create a typed representation from an untyped one? What needs to be added to F-omega to make it self-interpretable?

But if we continue our foray away from type theory, and into the world of computability, we find that there's a great deal more we can extract from these observations. If we generalize these results to even just the simply typed lambda calculus, we'll begin to reach the boundaries of the fundamental problems of computing—of Tarski's indefinability theorem. If it's impossible to implement a type checker as a constant function primitive, or it leads to contradictions then that answers our question. But if we are able to somehow implement a type checker as a constant primitive, then that would unlock an entire world of possibilities with respect to expressibility. Because, as Tarski observes, "No sufficiently powerful language is strongly-semantically-self-representational," so by somehow embedding this primitive into the language, we'd be able to \textit{increase} its expressibility, which has its own problems—for if this addition would strictly increase the power of the language, it would imply that we need another language more powerful to interpret this more powerful language, and so on and so forth. It's turtles all the way up. It would fundamentally change how we would define the expressibility of a language.

\section{References}
% Here you should acknowledge people whose help you are thankful
% for (and why), and any sources such as books and websites that
% you used when studying for the project.

TODO use an actual bibtex based reference format for automated citations
\begin{enumerate}
    \item Types and Programming Languages, Benjamin Pierce
    \item Brown and Palsberg, https://web.cs.ucla.edu/~palsberg/paper/popl16-full.pdf
    \item https://mathworld.wolfram.com/GoedelNumber.html
    \item Lambda Cube https://crypto.stanford.edu/~blynn/lambda/pts.html
    \item https://en.wikipedia.org/wiki/Tarski%27s_undefinability_theorem
    \item Shuo Ding and Qirun Zhang
\end{enumerate}

\appendixpage
LAMBDA CUBE + formal grammar of F-omega
\end{document}
